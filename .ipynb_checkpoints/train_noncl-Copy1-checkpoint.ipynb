{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf72b20-6cc9-47cc-9731-b4de06829f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n",
    "os.environ['WANDB_DISABLED'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad80de41-f067-4e6b-8973-510bfc386f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjs970612/anaconda3/envs/temp/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import random\n",
    "from transformers import ElectraForTokenClassification, AutoConfig, AutoTokenizer\n",
    "from transformers import AdamW\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset as DS\n",
    "from datasets import Dataset\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc379883-9ddf-4651-8c0b-6f8bbfcbfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.scheme import IOB1, IOB2, IOE1, IOE2, IOBES, BILOU, Entities, Prefix, Tag\n",
    "from seqeval.scheme import IOBES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b0a8c3-fdf6-42f5-b403-c3c322b97fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = [['ORG', 'PER', 'CVL', 'DAT', 'LOC', 'QNT'],\n",
    "               ['DAT', 'QNT', 'PER', 'LOC', 'ORG', 'CVL'],\n",
    "               ['CVL', 'LOC', 'ORG', 'QNT', 'DAT', 'PER'],\n",
    "               ['QNT', 'ORG', 'DAT', 'PER', 'CVL', 'LOC'],\n",
    "               ['LOC', 'CVL', 'QNT', 'ORG', 'PER', 'DAT'],\n",
    "               ['PER', 'DAT', 'LOC', 'CVL', 'QNT', 'ORG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8074d06b-b01d-4817-85fd-2d5c7f2a1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(DS):\n",
    "    def __init__(self, dataset, tokenizer, label2id, max_length):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2id = label2id\n",
    "        self.max_length = max_length\n",
    "        self.dataset = dataset\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(len(self.dataset['label'])):\n",
    "            text = dataset['label'][i]\n",
    "            tagged_words = re.findall('<.*?:.*?>', text)\n",
    "            \n",
    "            word2ids = dict()\n",
    "            for tagged_word in tagged_words:\n",
    "                tag_splited = tagged_word.strip('<>').split(':')\n",
    "                tag = tag_splited[-1]\n",
    "                word = ':'.join(tag_splited[:-1])\n",
    "                    \n",
    "                word_tok = self.tokenizer.encode(word)[1:-1]\n",
    "                if word not in word2ids:\n",
    "\n",
    "                    label_id = [self.label2id['B-'+tag]]\n",
    "                    if len(word_tok) > 1 :\n",
    "                        label_id.extend([self.label2id['I-'+tag]] * (len(word_tok)-1))\n",
    "                    word2ids[word] = {\n",
    "                        'target_ids': word_tok,\n",
    "                        'label_id': label_id \n",
    "                    }\n",
    "                    text = text.replace(tagged_word, word)\n",
    "\n",
    "            tokenized = self.tokenizer(text, truncation=True, max_length=self.max_length, padding='max_length')\n",
    "            if 0 in tokenized['input_ids']:\n",
    "                tok_length = tokenized['input_ids'].index(0)\n",
    "            else:\n",
    "                tok_length = self.max_length\n",
    "            label_input = tokenized['input_ids'][:tok_length]\n",
    "            labels = self._gen_labels(label_input, word2ids)\n",
    "            labels.insert(0, -100)\n",
    "            pad = [-100] * (self.max_length - len(labels))\n",
    "            labels.extend(pad)\n",
    "\n",
    "            temp = {\n",
    "                'input_ids' : tokenized['input_ids'],\n",
    "                'attention_mask' : tokenized['attention_mask'],\n",
    "                'labels' : labels\n",
    "            }\n",
    "            \n",
    "            self.data.append(temp)\n",
    "        \n",
    "    def _gen_labels(self, input_ids, word2ids):\n",
    "        sequence = input_ids[1:-1]\n",
    "        labels = [0] * len(sequence)\n",
    "        \n",
    "        for v in word2ids.values():\n",
    "            target_ids = v['target_ids']\n",
    "            label_id = v['label_id']\n",
    "            \n",
    "            i=0\n",
    "            target_ids_length = len(target_ids)\n",
    "            \n",
    "            while i < len(sequence):\n",
    "                if sequence[i:i + target_ids_length] == target_ids:\n",
    "                    labels[i:i + target_ids_length] = label_id\n",
    "                    i = i + target_ids_length\n",
    "                else:\n",
    "                    i += 1\n",
    "                    \n",
    "        return labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.data[idx]['input_ids'],\n",
    "            'attention_mask': self.data[idx]['attention_mask'],\n",
    "            'labels': self.data[idx]['labels'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908a8695-ba81-4689-be49-16613b8fd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IOBE(IOBES):\n",
    "    allowed_prefix = Prefix.I | Prefix.O | Prefix.B | Prefix.E\n",
    "    start_patterns = {\n",
    "        (Prefix.ANY, Prefix.B, Tag.ANY),\n",
    "        (Prefix.ANY, Prefix.S, Tag.ANY)\n",
    "    }\n",
    "    inside_patterns = {\n",
    "        (Prefix.B, Prefix.I, Tag.SAME),\n",
    "        (Prefix.B, Prefix.E, Tag.SAME),\n",
    "        (Prefix.I, Prefix.I, Tag.SAME),\n",
    "        (Prefix.I, Prefix.E, Tag.SAME)\n",
    "    }\n",
    "    end_patterns = {\n",
    "        (Prefix.S, Prefix.ANY, Tag.ANY),\n",
    "        (Prefix.E, Prefix.ANY, Tag.ANY),\n",
    "        (Prefix.B, Prefix.O, Tag.ANY),\n",
    "        (Prefix.B, Prefix.I, Tag.DIFF),\n",
    "        (Prefix.B, Prefix.B, Tag.ANY),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6beeb46d-081a-4420-91fd-d7fabe40fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    predictions = predictions.flatten()\n",
    "    labels = labels.flatten()\n",
    "    npre = []\n",
    "    nlab = []\n",
    " \n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != -100:\n",
    "            npre.append(predictions[i])\n",
    "            nlab.append(labels[i])\n",
    "    npre = torch.tensor(npre)\n",
    "    nlab = torch.tensor(nlab)\n",
    "    \n",
    "    label_indices = label_arr.copy()\n",
    "    npre = [label_indices[pred] for pred in npre]\n",
    "    nlab = [label_indices[label] for label in nlab]\n",
    "    del label_indices[label_indices.index(\"O\")]\n",
    "    entity_level_metrics = classification_report(\n",
    "        [nlab], [npre], digits=3,\n",
    "        suffix=False,\n",
    "        mode= 'strict', scheme=IOBE, \n",
    "        zero_division=True, output_dict=True\n",
    "    )\n",
    "\n",
    "    metrics = {}\n",
    "    #import pdb;pdb.set_trace()\n",
    "    for key in entity_level_metrics.keys():\n",
    "        if len(key) == 3:\n",
    "            metrics[key+\"_f1\"] = entity_level_metrics[key]['f1-score']\n",
    "            metrics[key+\"_recall\"] = entity_level_metrics[key]['recall']\n",
    "            metrics[key+\"_precision\"] = entity_level_metrics[key]['precision']\n",
    "            \n",
    "        if key == 'macro avg':\n",
    "            metrics[\"entity_macro_f1\"] = entity_level_metrics['macro avg']['f1-score']\n",
    "            metrics[\"entity_macro_precision\"] = entity_level_metrics['macro avg']['precision']\n",
    "            metrics[\"entity_macro_recall\"] = entity_level_metrics['macro avg']['recall']\n",
    "            \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cd3bc9-0688-40a5-9c0f-c662fe1f8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_train(config):\n",
    "    \n",
    "    model = ElectraForTokenClassification.from_pretrained(config['base_model_dir'], num_labels=13)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['base_model_dir'])\n",
    "    train_file = pd.read_csv(config['train_file'])\n",
    "    valid_file = pd.read_csv(config['valid_file'], sep='\\t') \n",
    "    \n",
    "    label2id = {'O':0}\n",
    "    count = 1\n",
    "    for i in range(6):\n",
    "        label2id['B-'+permutations[config['perm']][i]] = count\n",
    "        count += 1\n",
    "        label2id['I-'+permutations[config['perm']][i]] = count\n",
    "        count += 1\n",
    "\n",
    "    train_data = NERDataset(train_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    valid_data = NERDataset(valid_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    id2label = {label2id[label] : label for label in label2id.keys()}\n",
    "    \n",
    "    #import pdb;pdb.set_trace()\n",
    "    model.config.label2id = label2id\n",
    "    model.config.id2label = id2label\n",
    "\n",
    "    global label_arr\n",
    "    \n",
    "    label_arr = []\n",
    "    for v in id2label.values():\n",
    "        label_arr.append(v)\n",
    "        \n",
    "\n",
    "    data_collator = DefaultDataCollator()\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "     \n",
    "    training_args = TrainingArguments(\n",
    "\n",
    "        output_dir=config['output_dir'],\n",
    "        do_eval = True,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=config['train_epoch'],\n",
    "        weight_decay=0.1,\n",
    "        save_strategy = 'epoch',\n",
    "        logging_strategy = 'epoch',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        load_best_model_at_end = True,\n",
    "        label_names = ['labels'],\n",
    "        metric_for_best_model = 'entity_macro_f1',\n",
    "        warmup_ratio = 0.05,\n",
    "        no_cuda = False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset = valid_data,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer = tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(config['output_dir'] + '/final')\n",
    "    \n",
    "    for f_name in os.listdir(config['output_dir']):\n",
    "        if f_name.startswith('checkpoint'):\n",
    "            for f in os.listdir(config['output_dir']+'/'+f_name):\n",
    "                os.remove(config['output_dir']+'/'+f_name+'/'+f)\n",
    "            os.rmdir(config['output_dir']+'/'+f_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c442ff9a-94ac-499d-a5d6-b4e334edb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl_train(config):\n",
    "    \n",
    "    model = ElectraForTokenClassification.from_pretrained(config['base_model_dir'])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['base_model_dir'])\n",
    "    train_file = pd.read_csv(config['train_file'])\n",
    "    valid_file = pd.read_csv(config['valid_file'], sep='\\t') \n",
    "\n",
    "    label2id = model.config.label2id\n",
    "    \n",
    "    train_data = NERDataset(train_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    valid_data = NERDataset(valid_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    id2label = {label2id[label] : label for label in label2id.keys()}\n",
    "\n",
    "    global label_arr\n",
    "    \n",
    "    label_arr = []\n",
    "    for v in id2label.values():\n",
    "        label_arr.append(v)\n",
    "\n",
    "    data_collator = DefaultDataCollator()\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "     \n",
    "    training_args = TrainingArguments(\n",
    "\n",
    "        output_dir=config['output_dir'],\n",
    "        do_eval = True,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=config['train_epoch'],\n",
    "        weight_decay=0.1,\n",
    "        save_strategy = 'epoch',\n",
    "        logging_strategy = 'epoch',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        load_best_model_at_end = True,\n",
    "        label_names = ['labels'],\n",
    "        metric_for_best_model = 'entity_macro_f1',\n",
    "        warmup_ratio = 0.05,\n",
    "        no_cuda = False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset = valid_data,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer = tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(config['output_dir'] + '/final')\n",
    "    \n",
    "    for f_name in os.listdir(config['output_dir']):\n",
    "        if f_name.startswith('checkpoint'):\n",
    "            for f in os.listdir(config['output_dir']+'/'+f_name):\n",
    "                os.remove(config['output_dir']+'/'+f_name+'/'+f)\n",
    "            os.rmdir(config['output_dir']+'/'+f_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7696855e-e3ec-4fdc-a519-007e1c9c35a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    \n",
    "    model = ElectraForTokenClassification.from_pretrained(config['model'])\n",
    "    \n",
    "    global label_arr\n",
    "    \n",
    "    label_arr = []\n",
    "    for v in model.config.id2label.values():\n",
    "        label_arr.append(v)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['model'])\n",
    "    \n",
    "    test_file = pd.read_csv(config['test_file'], sep='\\t')\n",
    "    label2id = model.config.label2id\n",
    "    \n",
    "    test_dataset = NERDataset(test_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    \n",
    "    data_collator = DefaultDataCollator()\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=config['model'],\n",
    "        per_device_eval_batch_size=32,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        args=training_args,\n",
    "        model=model,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    metrics = trainer.evaluate(test_dataset)\n",
    "    trainer.save_metrics(split='test', metrics=metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1822a172-f989-49db-a4da-29781ecb78ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForTokenClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/jjs970612/anaconda3/envs/temp/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='2620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 720/2620 03:01 < 07:59, 3.96 it/s, Epoch 2.74/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Org F1</th>\n",
       "      <th>Org Recall</th>\n",
       "      <th>Org Precision</th>\n",
       "      <th>Entity Macro F1</th>\n",
       "      <th>Entity Macro Precision</th>\n",
       "      <th>Entity Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>0.306961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.339264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11756/2913127570.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 }\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mbase_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 base_config = {\n",
      "\u001b[0;32m/tmp/ipykernel_11756/3753721317.py\u001b[0m in \u001b[0;36mbase_train\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_dir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/temp/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         )\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/temp/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1987\u001b[0m                             self.accelerator.clip_grad_norm_(\n\u001b[1;32m   1988\u001b[0m                                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m                                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m                             )\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/temp/lib/python3.7/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         raise RuntimeError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if(__name__==\"__main__\"):\n",
    "    \n",
    "    for per_num_int in range(1,7):\n",
    "        per_num = str(per_num_int)\n",
    "        permutation_dir = \"train_data/perm_\" + per_num\n",
    "\n",
    "        data_file_dict = {\n",
    "            \"train\" : [],\n",
    "            \"valid\" : []\n",
    "        }\n",
    "\n",
    "        for i in range(6):\n",
    "            for f_name in os.listdir(permutation_dir + '/'):\n",
    "                if f_name.startswith('d'+str(i+1)):\n",
    "                    data_file_dict['train'].append(f_name)\n",
    "                    break\n",
    "\n",
    "            for f_name in os.listdir('test_data/perm' + str(per_num)):\n",
    "                if f_name.startswith('eval_'+str(i+1)):\n",
    "                    data_file_dict['valid'].append(f_name)\n",
    "                    break\n",
    "\n",
    "        for i in range(6):\n",
    "            if i == 0:\n",
    "                #import pdb;pdb.set_trace()\n",
    "                base_config = {\n",
    "                    'base_model_dir' : 'monologg/koelectra-base-v3-discriminator',\n",
    "                    'train_file' : permutation_dir + '/' + data_file_dict['train'][i],\n",
    "                    'valid_file' : 'test_data/perm' + str(per_num) + '/' + data_file_dict['valid'][i],\n",
    "                    'output_dir' : 'transfer/perm_' + per_num + '/step' + str(i+1),\n",
    "                    'train_epoch' : 10,\n",
    "                    'learning_rate' : 5e-05,\n",
    "                    'step' : i+1,\n",
    "                    'perm': per_num_int-1\n",
    "                }\n",
    "\n",
    "                base_train(base_config)\n",
    "            else:\n",
    "                base_config = {\n",
    "                    'base_model_dir' : 'transfer/perm_' + per_num + '/step' + str(i) + '/final',\n",
    "                    'train_file' : permutation_dir + '/' + data_file_dict['train'][i],\n",
    "                    'valid_file' : 'test_data/perm' + str(per_num) + '/' + data_file_dict['valid'][i],\n",
    "                    'output_dir' : 'transfer/perm_' + per_num + '/step' + str(i+1),\n",
    "                    'train_epoch' : 10,\n",
    "                    'learning_rate' : 5e-05,\n",
    "                    'step' : i+1,\n",
    "                    'perm': per_num_int-1\n",
    "                }\n",
    "                \n",
    "                cl_train(base_config)\n",
    "                \n",
    "            \n",
    "            test_config = {\n",
    "                'model':'transfer/perm_' + per_num + '/step' + str(i+1) + '/final',\n",
    "                'test_file': 'test_data/perm' + str(per_num) + '/' + data_file_dict['valid'][i]\n",
    "            }    \n",
    "\n",
    "            test(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fba42-0d7a-48e0-ab96-6a2992934dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
