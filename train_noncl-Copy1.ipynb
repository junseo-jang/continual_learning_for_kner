{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf72b20-6cc9-47cc-9731-b4de06829f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n",
    "os.environ['WANDB_DISABLED'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad80de41-f067-4e6b-8973-510bfc386f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import random\n",
    "from transformers import ElectraForTokenClassification, AutoConfig, AutoTokenizer\n",
    "from transformers import AdamW\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset as DS\n",
    "from datasets import Dataset\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc379883-9ddf-4651-8c0b-6f8bbfcbfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.scheme import IOB1, IOB2, IOE1, IOE2, IOBES, BILOU, Entities, Prefix, Tag\n",
    "from seqeval.scheme import IOBES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b0a8c3-fdf6-42f5-b403-c3c322b97fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = [['ORG', 'PER', 'CVL', 'DAT', 'LOC', 'QNT'],\n",
    "               ['DAT', 'QNT', 'PER', 'LOC', 'ORG', 'CVL'],\n",
    "               ['CVL', 'LOC', 'ORG', 'QNT', 'DAT', 'PER'],\n",
    "               ['QNT', 'ORG', 'DAT', 'PER', 'CVL', 'LOC'],\n",
    "               ['LOC', 'CVL', 'QNT', 'ORG', 'PER', 'DAT'],\n",
    "               ['PER', 'DAT', 'LOC', 'CVL', 'QNT', 'ORG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8074d06b-b01d-4817-85fd-2d5c7f2a1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(DS):\n",
    "    def __init__(self, dataset, tokenizer, label2id, max_length):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2id = label2id\n",
    "        self.max_length = max_length\n",
    "        self.dataset = dataset\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(len(self.dataset['label'])):\n",
    "            text = dataset['label'][i]\n",
    "            tagged_words = re.findall('<.*?:.*?>', text)\n",
    "            \n",
    "            word2ids = dict()\n",
    "            for tagged_word in tagged_words:\n",
    "                tag_splited = tagged_word.strip('<>').split(':')\n",
    "                tag = tag_splited[-1]\n",
    "                word = ':'.join(tag_splited[:-1])\n",
    "                    \n",
    "                word_tok = self.tokenizer.encode(word)[1:-1]\n",
    "                if word not in word2ids:\n",
    "\n",
    "                    label_id = [self.label2id['B-'+tag]]\n",
    "                    if len(word_tok) > 1 :\n",
    "                        label_id.extend([self.label2id['I-'+tag]] * (len(word_tok)-1))\n",
    "                    word2ids[word] = {\n",
    "                        'target_ids': word_tok,\n",
    "                        'label_id': label_id \n",
    "                    }\n",
    "                    text = text.replace(tagged_word, word)\n",
    "\n",
    "            tokenized = self.tokenizer(text, truncation=True, max_length=self.max_length, padding='max_length')\n",
    "            if 0 in tokenized['input_ids']:\n",
    "                tok_length = tokenized['input_ids'].index(0)\n",
    "            else:\n",
    "                tok_length = self.max_length\n",
    "            label_input = tokenized['input_ids'][:tok_length]\n",
    "            labels = self._gen_labels(label_input, word2ids)\n",
    "            labels.insert(0, -100)\n",
    "            pad = [-100] * (self.max_length - len(labels))\n",
    "            labels.extend(pad)\n",
    "\n",
    "            temp = {\n",
    "                'input_ids' : tokenized['input_ids'],\n",
    "                'attention_mask' : tokenized['attention_mask'],\n",
    "                'labels' : labels\n",
    "            }\n",
    "            \n",
    "            self.data.append(temp)\n",
    "        \n",
    "    def _gen_labels(self, input_ids, word2ids):\n",
    "        sequence = input_ids[1:-1]\n",
    "        labels = [0] * len(sequence)\n",
    "        \n",
    "        for v in word2ids.values():\n",
    "            target_ids = v['target_ids']\n",
    "            label_id = v['label_id']\n",
    "            \n",
    "            i=0\n",
    "            target_ids_length = len(target_ids)\n",
    "            \n",
    "            while i < len(sequence):\n",
    "                if sequence[i:i + target_ids_length] == target_ids:\n",
    "                    labels[i:i + target_ids_length] = label_id\n",
    "                    i = i + target_ids_length\n",
    "                else:\n",
    "                    i += 1\n",
    "                    \n",
    "        return labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.data[idx]['input_ids'],\n",
    "            'attention_mask': self.data[idx]['attention_mask'],\n",
    "            'labels': self.data[idx]['labels'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908a8695-ba81-4689-be49-16613b8fd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IOBE(IOBES):\n",
    "    allowed_prefix = Prefix.I | Prefix.O | Prefix.B | Prefix.E\n",
    "    start_patterns = {\n",
    "        (Prefix.ANY, Prefix.B, Tag.ANY),\n",
    "        (Prefix.ANY, Prefix.S, Tag.ANY)\n",
    "    }\n",
    "    inside_patterns = {\n",
    "        (Prefix.B, Prefix.I, Tag.SAME),\n",
    "        (Prefix.B, Prefix.E, Tag.SAME),\n",
    "        (Prefix.I, Prefix.I, Tag.SAME),\n",
    "        (Prefix.I, Prefix.E, Tag.SAME)\n",
    "    }\n",
    "    end_patterns = {\n",
    "        (Prefix.S, Prefix.ANY, Tag.ANY),\n",
    "        (Prefix.E, Prefix.ANY, Tag.ANY),\n",
    "        (Prefix.B, Prefix.O, Tag.ANY),\n",
    "        (Prefix.B, Prefix.I, Tag.DIFF),\n",
    "        (Prefix.B, Prefix.B, Tag.ANY),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6beeb46d-081a-4420-91fd-d7fabe40fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    predictions = predictions.flatten()\n",
    "    labels = labels.flatten()\n",
    "    npre = []\n",
    "    nlab = []\n",
    " \n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != -100:\n",
    "            npre.append(predictions[i])\n",
    "            nlab.append(labels[i])\n",
    "    npre = torch.tensor(npre)\n",
    "    nlab = torch.tensor(nlab)\n",
    "    \n",
    "    label_indices = label_arr.copy()\n",
    "    npre = [label_indices[pred] for pred in npre]\n",
    "    nlab = [label_indices[label] for label in nlab]\n",
    "    del label_indices[label_indices.index(\"O\")]\n",
    "    entity_level_metrics = classification_report(\n",
    "        [nlab], [npre], digits=3,\n",
    "        suffix=False,\n",
    "        mode= 'strict', scheme=IOBE, \n",
    "        zero_division=True, output_dict=True\n",
    "    )\n",
    "\n",
    "    metrics = {}\n",
    "    #import pdb;pdb.set_trace()\n",
    "    for key in entity_level_metrics.keys():\n",
    "        if len(key) == 3:\n",
    "            metrics[key+\"_f1\"] = entity_level_metrics[key]['f1-score']\n",
    "            metrics[key+\"_recall\"] = entity_level_metrics[key]['recall']\n",
    "            metrics[key+\"_precision\"] = entity_level_metrics[key]['precision']\n",
    "            \n",
    "        if key == 'macro avg':\n",
    "            metrics[\"entity_macro_f1\"] = entity_level_metrics['macro avg']['f1-score']\n",
    "            metrics[\"entity_macro_precision\"] = entity_level_metrics['macro avg']['precision']\n",
    "            metrics[\"entity_macro_recall\"] = entity_level_metrics['macro avg']['recall']\n",
    "            \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cd3bc9-0688-40a5-9c0f-c662fe1f8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_train(config):\n",
    "    \n",
    "    model = ElectraForTokenClassification.from_pretrained(config['base_model_dir'], num_labels=13)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['base_model_dir'])\n",
    "    train_file = pd.read_csv(config['train_file'])\n",
    "    valid_file = pd.read_csv(config['valid_file'], sep='\\t') \n",
    "    \n",
    "    label2id = {'O':0}\n",
    "    count = 1\n",
    "    for i in range(6):\n",
    "        label2id['B-'+permutations[config['perm']][i]] = count\n",
    "        count += 1\n",
    "        label2id['I-'+permutations[config['perm']][i]] = count\n",
    "        count += 1\n",
    "\n",
    "    train_data = NERDataset(train_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    valid_data = NERDataset(valid_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    id2label = {label2id[label] : label for label in label2id.keys()}\n",
    "    \n",
    "    #import pdb;pdb.set_trace()\n",
    "    model.config.label2id = label2id\n",
    "    model.config.id2label = id2label\n",
    "\n",
    "    global label_arr\n",
    "    \n",
    "    label_arr = []\n",
    "    for v in id2label.values():\n",
    "        label_arr.append(v)\n",
    "        \n",
    "\n",
    "    data_collator = DefaultDataCollator()\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "     \n",
    "    training_args = TrainingArguments(\n",
    "\n",
    "        output_dir=config['output_dir'],\n",
    "        do_eval = True,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=config['train_epoch'],\n",
    "        weight_decay=0.1,\n",
    "        save_strategy = 'epoch',\n",
    "        logging_strategy = 'epoch',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        load_best_model_at_end = True,\n",
    "        label_names = ['labels'],\n",
    "        metric_for_best_model = 'entity_macro_f1',\n",
    "        warmup_ratio = 0.05,\n",
    "        no_cuda = False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset = valid_data,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer = tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(config['output_dir'] + '/final')\n",
    "    \n",
    "    for f_name in os.listdir(config['output_dir']):\n",
    "        if f_name.startswith('checkpoint'):\n",
    "            for f in os.listdir(config['output_dir']+'/'+f_name):\n",
    "                os.remove(config['output_dir']+'/'+f_name+'/'+f)\n",
    "            os.rmdir(config['output_dir']+'/'+f_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c442ff9a-94ac-499d-a5d6-b4e334edb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl_train(config):\n",
    "    \n",
    "    #model = ElectraForTokenClassification.from_pretrained(config['base_model_dir'], num_labgels=(config['step']-1)*2+1)\n",
    "    model = ElectraForTokenClassification.from_pretrained(config['base_model_dir'])\n",
    "    # new_layer = nn.Linear(512, config['step']*2+1)\n",
    "    # new_layer.weight.data[:(config['step']-1)*2+1,:] = model.classifier.weight.data\n",
    "    # model.classifer = new_layer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['base_model_dir'])\n",
    "    train_file = pd.read_csv(config['train_file'])\n",
    "    valid_file = pd.read_csv(config['valid_file'], sep='\\t') \n",
    "\n",
    "    label2id = {'O':0}\n",
    "    count = 1\n",
    "    for i in range(6):\n",
    "        label2id['B-'+permutations[config['perm']][i]] = count\n",
    "        count += 1\n",
    "        label2id['I-'+permutations[config['perm']][i]] = count\n",
    "        count += 1\n",
    "\n",
    "    \n",
    "    train_data = NERDataset(train_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    valid_data = NERDataset(valid_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    id2label = {label2id[label] : label for label in label2id.keys()}\n",
    "    \n",
    "    # model.config.label2id = label2id\n",
    "    # model.config.id2label = id2label\n",
    "\n",
    "    global label_arr\n",
    "    \n",
    "    label_arr = []\n",
    "    for v in id2label.values():\n",
    "        label_arr.append(v)\n",
    "\n",
    "    data_collator = DefaultDataCollator()\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "     \n",
    "    training_args = TrainingArguments(\n",
    "\n",
    "        output_dir=config['output_dir'],\n",
    "        do_eval = True,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=config['train_epoch'],\n",
    "        weight_decay=0.1,\n",
    "        save_strategy = 'epoch',\n",
    "        logging_strategy = 'epoch',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        load_best_model_at_end = True,\n",
    "        label_names = ['labels'],\n",
    "        metric_for_best_model = 'entity_macro_f1',\n",
    "        warmup_ratio = 0.05,\n",
    "        no_cuda = False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset = valid_data,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer = tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(config['output_dir'] + '/final')\n",
    "    \n",
    "    for f_name in os.listdir(config['output_dir']):\n",
    "        if f_name.startswith('checkpoint'):\n",
    "            for f in os.listdir(config['output_dir']+'/'+f_name):\n",
    "                os.remove(config['output_dir']+'/'+f_name+'/'+f)\n",
    "            os.rmdir(config['output_dir']+'/'+f_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7696855e-e3ec-4fdc-a519-007e1c9c35a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    \n",
    "    model = ElectraForTokenClassification.from_pretrained(config['model'])\n",
    "    \n",
    "    global label_arr\n",
    "    \n",
    "    label_arr = []\n",
    "    for v in model.config.id2label.values():\n",
    "        label_arr.append(v)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['model'])\n",
    "    \n",
    "    test_file = pd.read_csv(config['test_file'], sep='\\t')\n",
    "    label2id = model.config.label2id\n",
    "    \n",
    "    test_dataset = NERDataset(test_file, tokenizer=tokenizer, max_length=300, label2id=label2id)\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    \n",
    "    data_collator = DefaultDataCollator()\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=config['model'],\n",
    "        per_device_eval_batch_size=32,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        args=training_args,\n",
    "        model=model,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    metrics = trainer.evaluate(test_dataset)\n",
    "    trainer.save_metrics(split='test', metrics=metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1822a172-f989-49db-a4da-29781ecb78ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2620' max='2620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2620/2620 11:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cvl F1</th>\n",
       "      <th>Cvl Recall</th>\n",
       "      <th>Cvl Precision</th>\n",
       "      <th>Dat F1</th>\n",
       "      <th>Dat Recall</th>\n",
       "      <th>Dat Precision</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Entity Macro F1</th>\n",
       "      <th>Entity Macro Precision</th>\n",
       "      <th>Entity Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.755121</td>\n",
       "      <td>0.831583</td>\n",
       "      <td>0.843497</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207896</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.210874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.772937</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>0.910360</td>\n",
       "      <td>0.824900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216381</td>\n",
       "      <td>0.956225</td>\n",
       "      <td>0.227590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.884716</td>\n",
       "      <td>0.870871</td>\n",
       "      <td>0.852314</td>\n",
       "      <td>0.890253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217718</td>\n",
       "      <td>0.972563</td>\n",
       "      <td>0.213079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.895565</td>\n",
       "      <td>0.856089</td>\n",
       "      <td>0.937546</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214022</td>\n",
       "      <td>0.946914</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.923057</td>\n",
       "      <td>0.882941</td>\n",
       "      <td>0.908891</td>\n",
       "      <td>0.858432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220735</td>\n",
       "      <td>0.964608</td>\n",
       "      <td>0.227223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.947555</td>\n",
       "      <td>0.882457</td>\n",
       "      <td>0.918442</td>\n",
       "      <td>0.849185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220614</td>\n",
       "      <td>0.962296</td>\n",
       "      <td>0.229611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.986870</td>\n",
       "      <td>0.891281</td>\n",
       "      <td>0.912564</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222820</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.228141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.989217</td>\n",
       "      <td>0.880702</td>\n",
       "      <td>0.922116</td>\n",
       "      <td>0.842848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220175</td>\n",
       "      <td>0.960712</td>\n",
       "      <td>0.230529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.996134</td>\n",
       "      <td>0.886759</td>\n",
       "      <td>0.917708</td>\n",
       "      <td>0.857830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221690</td>\n",
       "      <td>0.964457</td>\n",
       "      <td>0.229427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.998169</td>\n",
       "      <td>0.884099</td>\n",
       "      <td>0.919177</td>\n",
       "      <td>0.851600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221025</td>\n",
       "      <td>0.962900</td>\n",
       "      <td>0.229794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [95/95 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2620' max='2620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2620/2620 11:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cvl F1</th>\n",
       "      <th>Cvl Recall</th>\n",
       "      <th>Cvl Precision</th>\n",
       "      <th>Dat F1</th>\n",
       "      <th>Dat Recall</th>\n",
       "      <th>Dat Precision</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Qnt F1</th>\n",
       "      <th>Qnt Recall</th>\n",
       "      <th>Qnt Precision</th>\n",
       "      <th>Entity Macro F1</th>\n",
       "      <th>Entity Macro Precision</th>\n",
       "      <th>Entity Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>1.163131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.151140</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.157823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.200190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759644</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.673684</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>0.934737</td>\n",
       "      <td>0.174150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.246466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822006</td>\n",
       "      <td>0.863946</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.164401</td>\n",
       "      <td>0.956790</td>\n",
       "      <td>0.172789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.291755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768328</td>\n",
       "      <td>0.891156</td>\n",
       "      <td>0.675258</td>\n",
       "      <td>0.153666</td>\n",
       "      <td>0.935052</td>\n",
       "      <td>0.178231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.312481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.174150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.339807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809969</td>\n",
       "      <td>0.884354</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.161994</td>\n",
       "      <td>0.949425</td>\n",
       "      <td>0.176871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.353956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836013</td>\n",
       "      <td>0.884354</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.958537</td>\n",
       "      <td>0.176871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.379888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845902</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.169180</td>\n",
       "      <td>0.963291</td>\n",
       "      <td>0.175510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.379584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>0.165161</td>\n",
       "      <td>0.957055</td>\n",
       "      <td>0.174150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.383638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>0.165161</td>\n",
       "      <td>0.957055</td>\n",
       "      <td>0.174150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [95/95 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2620' max='2620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2620/2620 12:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cvl F1</th>\n",
       "      <th>Cvl Recall</th>\n",
       "      <th>Cvl Precision</th>\n",
       "      <th>Dat F1</th>\n",
       "      <th>Dat Recall</th>\n",
       "      <th>Dat Precision</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Org F1</th>\n",
       "      <th>Org Recall</th>\n",
       "      <th>Org Precision</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Qnt F1</th>\n",
       "      <th>Qnt Recall</th>\n",
       "      <th>Qnt Precision</th>\n",
       "      <th>Entity Macro F1</th>\n",
       "      <th>Entity Macro Precision</th>\n",
       "      <th>Entity Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>1.352348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771473</td>\n",
       "      <td>0.948784</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128579</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.158131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>1.582582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848635</td>\n",
       "      <td>0.875800</td>\n",
       "      <td>0.823105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141439</td>\n",
       "      <td>0.970517</td>\n",
       "      <td>0.145967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>1.685463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857508</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.855867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142918</td>\n",
       "      <td>0.975978</td>\n",
       "      <td>0.143192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.757653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857316</td>\n",
       "      <td>0.903969</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142886</td>\n",
       "      <td>0.969207</td>\n",
       "      <td>0.150662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.889577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860149</td>\n",
       "      <td>0.889885</td>\n",
       "      <td>0.832335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143358</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>0.148314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.900879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862840</td>\n",
       "      <td>0.914213</td>\n",
       "      <td>0.816934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>0.969489</td>\n",
       "      <td>0.152369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.931900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856802</td>\n",
       "      <td>0.919334</td>\n",
       "      <td>0.802235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.967039</td>\n",
       "      <td>0.153222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.933947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848520</td>\n",
       "      <td>0.935980</td>\n",
       "      <td>0.776008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141420</td>\n",
       "      <td>0.962668</td>\n",
       "      <td>0.155997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.959331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865817</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.823326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144303</td>\n",
       "      <td>0.970554</td>\n",
       "      <td>0.152155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.970217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.969524</td>\n",
       "      <td>0.152582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [95/95 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if(__name__==\"__main__\"):\n",
    "    \n",
    "    for per_num_int in range(6,7):\n",
    "        per_num = str(per_num_int)\n",
    "        permutation_dir = \"train_data/perm_\" + per_num\n",
    "\n",
    "        data_file_dict = {\n",
    "            \"train\" : [],\n",
    "            \"valid\" : []\n",
    "        }\n",
    "\n",
    "        for i in range(6):\n",
    "            for f_name in os.listdir(permutation_dir + '/'):\n",
    "                if f_name.startswith('d'+str(i)):\n",
    "                    data_file_dict['train'].append(f_name)\n",
    "                    break\n",
    "\n",
    "            for f_name in os.listdir('test_data/perm' + str(per_num)):\n",
    "                if f_name.startswith('eval_'+str(i+1)):\n",
    "                    data_file_dict['valid'].append(f_name)\n",
    "                    break\n",
    "\n",
    "        for i in range(3, 6):\n",
    "            if i == 0:\n",
    "                #import pdb;pdb.set_trace()\n",
    "                base_config = {\n",
    "                    'base_model_dir' : 'monologg/koelectra-base-v3-discriminator',\n",
    "                    'train_file' : permutation_dir + '/' + data_file_dict['train'][i],\n",
    "                    'valid_file' : 'test_data/perm' + str(per_num) + '/' + data_file_dict['valid'][i],\n",
    "                    'output_dir' : 'transfer/perm_' + per_num + '/step' + str(i+1),\n",
    "                    'train_epoch' : 10,\n",
    "                    'learning_rate' : 5e-05,\n",
    "                    'step' : i+1,\n",
    "                    'perm': per_num_int-1\n",
    "                }\n",
    "\n",
    "                base_train(base_config)\n",
    "            else:\n",
    "                base_config = {\n",
    "                    'base_model_dir' : 'transfer/perm_' + per_num + '/step' + str(i) + '/final',\n",
    "                    'train_file' : permutation_dir + '/' + data_file_dict['train'][i],\n",
    "                    'valid_file' : 'test_data/perm' + str(per_num) + '/' + data_file_dict['valid'][i],\n",
    "                    'output_dir' : 'transfer/perm_' + per_num + '/step' + str(i+1),\n",
    "                    'train_epoch' : 10,\n",
    "                    'learning_rate' : 5e-05,\n",
    "                    'step' : i+1,\n",
    "                    'perm': per_num_int-1\n",
    "                }\n",
    "                \n",
    "                cl_train(base_config)\n",
    "                \n",
    "            \n",
    "            test_config = {\n",
    "                'model':'transfer/perm_' + per_num + '/step' + str(i+1) + '/final',\n",
    "                'test_file': 'test_data/perm' + str(per_num) + '/' + data_file_dict['valid'][i]\n",
    "            }    \n",
    "\n",
    "            test(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd6df2-61fe-4e3d-a3d5-140c0f433301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
